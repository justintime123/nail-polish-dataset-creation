{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (4.23.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from selenium) (0.26.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from selenium) (2024.7.4)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from trio~=0.17->selenium) (24.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: requests in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: pandas in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: bs4 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/justinchassin/Desktop/my-python3-env/lib/python3.12/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "! pip3 install selenium\n",
    "! pip3 install requests\n",
    "! pip3 install pandas\n",
    "! pip3 install bs4\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "!python --version\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HTML\n",
    "#List of products is in product-collection-list_products class \n",
    "#In each product (product-list-item_title), need the product name and description\n",
    "#Description is found in link and product name is in span\n",
    "\n",
    "#Scraping URL to understand how to get info for one nail polish\n",
    "#https://www.essie.com/nail-polish/enamel/yellows\n",
    "\n",
    "#https://www.geeksforgeeks.org/beautifulsoup-scraping-link-from-html/\n",
    "#https://stackoverflow.com/questions/56455255/beautifulsoup-find-all-returns-nothing\n",
    "\n",
    "def getHTMLDocument(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def get_links_by_product(url_to_scrape, html_class_to_look_for, web_driver=None): \n",
    "    html_doc = web_driver.page_source if web_driver else getHTMLDocument(url_to_scrape)\n",
    "    #print(html_doc)\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    polish_list = soup.find_all(\"a\", html_class_to_look_for)\n",
    "    #print(polish_list)\n",
    "    \n",
    "    html_base = 'https://www.essie.com'\n",
    "\n",
    "    links_by_product = {}\n",
    "    for i in range(len(polish_list)):\n",
    "        name = polish_list[i].span.text\n",
    "        relative_link = polish_list[i].get(\"href\")\n",
    "        link = html_base + relative_link #adjusting HTML path to make it absolute\n",
    "        links_by_product[name] = link #this assumes all nail polish names are unique\n",
    "    return links_by_product\n",
    "\n",
    "\n",
    "\n",
    "url_to_scrape = 'https://www.essie.com/nail-polish/enamel/yellows'\n",
    "html_class_to_look_for = \"product-list-item__title\"\n",
    "links_by_product = get_links_by_product(url_to_scrape, html_class_to_look_for)\n",
    "links_by_product\n",
    "\n",
    "#Rewriting using list comprehension\n",
    "###links_by_product = [polish.name:base.append(polish.link) for polish in yellow_polishes]\n",
    "# links_by_product = {yellow_polishes[item].span.text: yellow_polishes[item].get(\"href\")\n",
    "#                    for item in yellow_polishes}\n",
    "#yellow_polishes[0].span.text\n",
    "#yellow_polishes[0].get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brainstorm of fields to collect for each polish\n",
    "\n",
    "#Description\n",
    "#Tags: color,finish and formula_type (eg, longwear, quick-dry, enamel). Some products might have multiple formula types (e.g., blanc is available in enamel or gel)\n",
    "#Is the product discontinued?\n",
    "#Reviews \n",
    "#Best-seller?\n",
    "\n",
    "#Goal: Collect standardized data of nail polish colors across companies, so that they can be compared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing generic function\n",
    "def get_tags_for_product(product_url):\n",
    "    #Calls find_all function in Beautiful Soup\n",
    "    html_doc = getHTMLDocument(product_url)\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    matching_elements = soup.find_all(\"li\", \"product-detail-info__tag\")\n",
    "    #matching_elements = soup.find_all(\"a\", \"tag__link\")\n",
    "    list_of_tags = [tag.text.replace('\\n', '') for tag in matching_elements]\n",
    "    return list_of_tags\n",
    "    \n",
    "\n",
    "#Getting tags for each polish\n",
    "#Each tag is in li of product-detail-info__tag class\n",
    "polish_descriptions = {}\n",
    "for polish_name,link in links_by_product.items():\n",
    "    tags = get_tags_for_product(link)\n",
    "    polish_descriptions[polish_name] = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above, 'light and fairy' has color_family last and polish_type first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figuring out how to parse all elements in \"select color family\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polish_descriptions['born to adorn'][0].get(\"cta_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Potential research questions (extensions)\n",
    "#How do the best-sellers change with each season?\n",
    "#How does the distribution of available colors differ between companies like Essie, OPI and Orly?\n",
    "#Are there certain color categories or attributes that predict discontinuation or have historically been discontinued?\n",
    "#For the above question, are there similar predictors for best-sellers?\n",
    "#The above questions can be combined in different ways\n",
    "\n",
    "#Things to figure out\n",
    "#Breaking down color categories into sub-categories\n",
    "#How to handle undertones \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get all of the polishes in one go, I decided to parse from the \"shop-all section\" ().\n",
    "#The tags for each product might not come in order (like 'light and fairy' above), so I'll collect all possible filters first, so I can reorder the sets appropriately.\n",
    "\n",
    "def getHTMLDocument(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "url_to_scrape = \"https://www.essie.com/shop-all\"\n",
    "get_links_by_product(url_to_scrape, \"product-grid-item__name\") #have to adapt to use Selenium. Inspect shows final DOM, but BS is parsing HTML downloaded from server.\n",
    "#The products in shop-all are dynamically generated using JS.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update # to update ubuntu to correctly run apt install\n",
    "# !apt install -y chromium-chromedriver\n",
    "# !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install chromedriver\n",
    "#cService = Service(executable_path='/chromedriver/chromedriver.exe')\n",
    "#options = webdriver.ChromeOptions()\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.essie.com/shop-all')\n",
    "#time.sleep(10)\n",
    "\n",
    "def get_links_by_product_v2(url_to_scrape, html_class_to_look_for, web_driver=None): \n",
    "    html_doc = web_driver.page_source if web_driver else getHTMLDocument(url_to_scrape)\n",
    "    #print(html_doc)\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    polish_list = soup.find_all(\"a\", html_class_to_look_for)\n",
    "    #print(polish_list)\n",
    "    \n",
    "    html_base = 'https://www.essie.com'\n",
    "\n",
    "    links_by_product = {}\n",
    "    for i in range(len(polish_list)):\n",
    "        name = polish_list[i].text.strip().replace('\\n', '')\n",
    "        relative_link = polish_list[i].get(\"href\")\n",
    "        link = html_base + relative_link #adjusting HTML path to make it absolute\n",
    "        links_by_product[name] = link #this assumes all nail polish names are unique\n",
    "    return links_by_product\n",
    "\n",
    "\n",
    "\n",
    "page_1 = get_links_by_product_v2(url_to_scrape='https://www.essie.com/shop-all', html_class_to_look_for=\"product-grid-item__name\", web_driver=driver) #have to adapt to use Selenium. Inspect shows final DOM, but BS is parsing HTML downloaded from server.\n",
    "\n",
    "#https://stackoverflow.com/questions/36244877/python-selenium-clicking-next-button-until-the-end\n",
    "#Using Selenium to click on 'Next Page'\n",
    "#https://stackoverflow.com/questions/46669850/using-aria-label-to-locate-and-click-an-element-with-python3-and-selenium\n",
    "\n",
    "next_btn = driver.find_element(By.CSS_SELECTOR, \"[aria-label='Next Page']\")\n",
    "next_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extending above function to collect rest of the colors\n",
    "!python --version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPI brainstorm \n",
    "#Product types: Nail Lacquer, Infinite Shine, Gel, Vegan (Natural Origin Nail Lacquer)\n",
    "#Potentially use Essie's finish categories and parse descriptions to get finish types\n",
    "#Or more easily, for product_type, select each color and finish\n",
    "#Use Selenium to automate these selections and parse website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.opi.com/collections/shop-products?color=Red&finish=Cr%C3%A8me&product-type=Nail%20Lacquer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.opi.com/collections/shop-products\n",
    "#https://www.opi.com/collections/nail-colors\n",
    "#https://selenium-python.readthedocs.io/locating-elements.html\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.opi.com/collections/shop-products')\n",
    "time.sleep(10)\n",
    "\n",
    "#XPATH: //*[@id=\"main\"]/section[2]/div/div/div[1]/button \n",
    "next_btn = driver.find_element(By.XPATH, \"//*[@id='button--:r0:--3']\")\n",
    "next_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attrs_by_prod = [prod.attrs for prod in polish_list]\n",
    "#type(polish_list[0])\n",
    "#polish_list[0].to_dict()\n",
    "#attrs_by_prod\n",
    "#data-color-system = Collection\n",
    "#Add collection and product name to attrs_by_prod\n",
    "#Gay movie analysis: How have top titles changed for Rotten Tomatoes over time? \n",
    "#https://www.rottentomatoes.com/browse/tv_series_browse/genres:lgbtq~sort:popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to get attributes for each item in OPI website\n",
    "import time\n",
    "\n",
    "def get_each_by_opi_product_tag(driver):\n",
    "    #driver.get(url_to_scrape)\n",
    "    #time.sleep(10)\n",
    "    html_doc = driver.page_source\n",
    "    #print(html_doc)\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    polish_list = soup.find_all(\"a\", \"productCard__titles\")  #find_all also gets descendents\n",
    "    return polish_list\n",
    "\n",
    "def get_attrs_for_product(prod_dict):\n",
    "    return dict((k, prod_dict[k]) for k in attrs_to_parse)\n",
    "\n",
    "def get_product_type_and_name(prod_tag):\n",
    "    #getting Product Type and Product names, using contents\n",
    "    #https://stackoverflow.com/questions/25251841/bs4-getting-text-in-tag\n",
    "    return {'product-type': prod_tag.contents[0].text, \n",
    "            'product-name': prod_tag.contents[1].text}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all prods in polish_list, get below attrs and parse for Product Type/Product Name\n",
    "attrs_to_parse = ['data-color-family-primary',\n",
    " #'data-color-family-secondary',\n",
    " 'data-color-subgroup',\n",
    " 'data-color-finish',\n",
    " #'data-color-depth',\n",
    " #'data-color-hex',\n",
    " 'data-color-system',\n",
    "'href' #will use hrefs to later parse descriptions for each product, opi.com/products/href[-1]\n",
    "]\n",
    "\n",
    "#polish_list[0].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def get_attrs_by_product(driver):\n",
    "    product_tags = get_each_by_opi_product_tag(driver)\n",
    "    attrs_by_prod = [get_attrs_for_product(prod.attrs) | get_product_type_and_name(prod) for prod in product_tags]\n",
    "    return attrs_by_prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome()\n",
    "# #url_to_scrape = 'https://www.opi.com/collections/shop-products?color=Red&finish=Cr%C3%A8me&product-type=Nail%20Lacquer'\n",
    "# url_to_scrape = 'https://www.opi.com/collections/shop-products?product-type=Nail%20Lacquer--Infinite%20Shine'\n",
    "\n",
    "# # try:\n",
    "# #     WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'onetrust-accept-btn-handler'))).click()\n",
    "# #     time.sleep(random.random()*10)\n",
    "# #     WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"main\"]/div[4]/section/div[2]/button'))).click()\n",
    "# #     time.sleep(random.random()*10)\n",
    "# # except:\n",
    "# #     driver.quit()\n",
    "\n",
    "# #time.sleep(random.random()*10)\n",
    "# #print(get_attrs_by_product(driver, url_to_scrape))\n",
    "# #driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polish_list[0]['data-color-finish']\n",
    "#Using Selenium to click \"Show More\" button\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "from random import randint\n",
    "\n",
    "\n",
    "#Dismiss cookies window\n",
    "#https://stackoverflow.com/questions/64032271/handling-accept-cookies-popup-with-selenium-in-python\n",
    "#https://stackoverflow.com/questions/59130200/selenium-wait-until-element-is-present-visible-and-interactable\n",
    "\n",
    "#Div id: onetrust-button-group\n",
    "#button id: onetrust-reject-all-handler\n",
    "#onetrust-accept-btn-handler\n",
    "\n",
    "#//*[@id=\"main\"]/div[4]/section/div[2]/button\n",
    "\n",
    "def click_show_more_btn(driver, url_has_page_number=False):\n",
    "    time.sleep(randint(15, 20))\n",
    "    #if url_has_page_number, there will be two load buttons and the xpath is different\n",
    "    xpath = ' //*[@id=\"main\"]/div[4]/section/div[3]/button' if url_has_page_number else '//*[@id=\"main\"]/div[4]/section/div[2]/button'\n",
    "    WebDriverWait(driver, randint(15, 20)).until(EC.element_to_be_clickable((By.XPATH, xpath))).click()\n",
    "\n",
    "def get_products_from_site(start_page=1, end_page=None):\n",
    "    driver = webdriver.Chrome()\n",
    "    url_to_scrape = ''\n",
    "    url_has_page_number = False\n",
    "    \n",
    "    if start_page > 1:\n",
    "        url_to_scrape = f\"https://www.opi.com/collections/shop-products?page={start_page}&product-type=Nail%20Lacquer--Infinite%20Shine--Natural%20Origin%20Nail%20Lacquer\"\n",
    "        url_has_page_number = True\n",
    "    else: \n",
    "        url_to_scrape = \"https://www.opi.com/collections/shop-products?product-type=Nail%20Lacquer--Infinite%20Shine--Natural%20Origin%20Nail%20Lacquer\"\n",
    "    driver.get(url_to_scrape)\n",
    "    \n",
    "    try:\n",
    "        #Dismiss cookies pop-up\n",
    "        WebDriverWait(driver, randint(10, 15)).until(EC.element_to_be_clickable((By.ID, 'onetrust-accept-btn-handler'))).click()\n",
    "    \n",
    "        #if end_page is None, click thru until the last page\n",
    "        if end_page is None:\n",
    "            while True:\n",
    "                try:\n",
    "                    click_show_more_btn(driver, url_has_page_number)\n",
    "                except TimeoutException:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            num_clicks = end_page-start_page\n",
    "            #Click show-more button\n",
    "            for i in range(num_clicks):\n",
    "                click_show_more_btn(driver, url_has_page_number)\n",
    "        \n",
    "        #Get product results\n",
    "        time.sleep(randint(30, 40))\n",
    "        prods = get_attrs_by_product(driver)\n",
    "        #Write results to json file\n",
    "        end_page = 25\n",
    "        output_file = f\"opi_products_pages_{start_page}_thru_{end_page}.json\"\n",
    "        with open(output_file, 'w') as fp:\n",
    "            json.dump(prods, fp)\n",
    "        driver.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        driver.quit()\n",
    "    \n",
    "#get_products_from_site(num_pages_to_parse=5)\n",
    "#get_products_from_site(start_page=6, end_page=10)\n",
    "#get_products_from_site(start_page=11, end_page=15)\n",
    "#get_products_from_site(start_page=16, end_page=20)\n",
    "get_products_from_site(start_page=1)\n",
    "\n",
    "                                \n",
    "# accept_cookies_btn = driver.find_element(By.ID, 'onetrust-reject-all-handler')\n",
    "# accept_cookies_btn.click()\n",
    "\n",
    "\n",
    "#show_more_button = driver.find_element(By.CLASS_NAME, 'Button_button__v0_QK')\n",
    "#show_more_button.click()\n",
    "#Cookies window appears to be in the way\n",
    "#https://stackoverflow.com/questions/43868009/how-to-resolve-elementnotinteractableexception-element-is-not-visible-in-seleni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "my-python3.12-kernel",
   "language": "python",
   "name": "my-python3.12-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
